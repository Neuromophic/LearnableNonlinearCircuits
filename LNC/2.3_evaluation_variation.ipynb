{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import calendar\n",
    "import numpy as np\n",
    "import config\n",
    "import training \n",
    "import matplotlib.pyplot as plt\n",
    "import evaluation as E\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dataset_Pendigits.p',\n",
       " 'Dataset_acuteinflammation.p',\n",
       " 'Dataset_balancescale.p',\n",
       " 'Dataset_breastcancerwisc.p',\n",
       " 'Dataset_cardiotocography3clases.p',\n",
       " 'Dataset_energyy1.p',\n",
       " 'Dataset_energyy2.p',\n",
       " 'Dataset_iris.p',\n",
       " 'Dataset_mammographic.p',\n",
       " 'Dataset_seeds.p',\n",
       " 'Dataset_tictactoe.p',\n",
       " 'Dataset_vertebralcolumn2clases.p',\n",
       " 'Dataset_vertebralcolumn3clases.p']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = os.listdir('./dataset')\n",
    "datasets = [f for f in datasets if (f.startswith('Dataset') and f.endswith('.p'))]\n",
    "datasets.sort()\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [1,2,3,4,5,6,7,8,9,10]\n",
    "test_epsilons = [0, 0.05, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# non-variation aware (nominal) training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epsilon = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 10, 4, 2])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = torch.zeros([13, 10, len(test_epsilons), 2])\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, test_epsilon in enumerate(test_epsilons):\n",
    "    for d, dataset in enumerate(datasets):\n",
    "        datapath = os.path.join(f'./dataset/{dataset}')\n",
    "        with open(datapath, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        X_train    = data['X_train']\n",
    "        y_train    = data['y_train']\n",
    "        X_valid    = data['X_valid']\n",
    "        y_valid    = data['y_valid']\n",
    "        X_test     = data['X_test']\n",
    "        y_test     = data['y_test']\n",
    "        data_name  = data['name']\n",
    "\n",
    "        N_class    = data['n_class']\n",
    "        N_feature  = data['n_feature']\n",
    "        N_train    = X_train.shape[0]\n",
    "        N_valid    = X_valid.shape[0]\n",
    "        N_test     = X_test.shape[0]\n",
    "\n",
    "        # generate tensordataset\n",
    "        trainset = TensorDataset(X_train, y_train)\n",
    "        validset = TensorDataset(X_valid, y_valid)\n",
    "        testset  = TensorDataset(X_test, y_test)\n",
    "\n",
    "        # batch\n",
    "        train_loader = DataLoader(trainset, batch_size=N_train)\n",
    "        valid_loader = DataLoader(validset, batch_size=N_valid)\n",
    "        test_loader  = DataLoader(testset,  batch_size=N_test)\n",
    "\n",
    "        for s, seed in enumerate(seeds):\n",
    "            setup = f'dataset:{data_name}_epsilon:{train_epsilon}_seed:{seed}'\n",
    "            model = torch.load(f'./results_variation/pNN_{setup}')\n",
    "            model.SetParameter('N', config.N_test)\n",
    "            model.SetParameter('epsilon', test_epsilon)\n",
    "            acc, std = E.BASIC_variation(model, X_test, y_test)\n",
    "            results[d,s,e,0], results[d,s,e,1] = acc, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.mean(results, dim=[1])\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, test_epsilon in enumerate(test_epsilons):\n",
    "    print(f'Under {test_epsilon*100}% production error:')\n",
    "    print(np.round(results[:,e,0].numpy(),2) ,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5% variation aware training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epsilon = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 10, 4, 2])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = torch.zeros([13, 10, len(test_epsilons), 2])\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, test_epsilon in enumerate(test_epsilons):\n",
    "    for d, dataset in enumerate(datasets):\n",
    "        datapath = os.path.join(f'./dataset/{dataset}')\n",
    "        with open(datapath, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        X_train    = data['X_train']\n",
    "        y_train    = data['y_train']\n",
    "        X_valid    = data['X_valid']\n",
    "        y_valid    = data['y_valid']\n",
    "        X_test     = data['X_test']\n",
    "        y_test     = data['y_test']\n",
    "        data_name  = data['name']\n",
    "\n",
    "        N_class    = data['n_class']\n",
    "        N_feature  = data['n_feature']\n",
    "        N_train    = X_train.shape[0]\n",
    "        N_valid    = X_valid.shape[0]\n",
    "        N_test     = X_test.shape[0]\n",
    "\n",
    "        # generate tensordataset\n",
    "        trainset = TensorDataset(X_train, y_train)\n",
    "        validset = TensorDataset(X_valid, y_valid)\n",
    "        testset  = TensorDataset(X_test, y_test)\n",
    "\n",
    "        # batch\n",
    "        train_loader = DataLoader(trainset, batch_size=N_train)\n",
    "        valid_loader = DataLoader(validset, batch_size=N_valid)\n",
    "        test_loader  = DataLoader(testset,  batch_size=N_test)\n",
    "\n",
    "        for s, seed in enumerate(seeds):\n",
    "            setup = f'dataset:{data_name}_epsilon:{train_epsilon}_seed:{seed}'\n",
    "            model = torch.load(f'./results_variation/pNN_{setup}')\n",
    "            model.SetParameter('N', config.N_test)\n",
    "            model.SetParameter('epsilon', test_epsilon)\n",
    "            acc, std = E.BASIC_variation(model, X_test, y_test)\n",
    "            results[d,s,e,0], results[d,s,e,1] = acc, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 4, 2])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = torch.mean(results, dim=[1])\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under 0% production error:\n",
      "[0.57 1.   0.81 0.97 0.84 0.94 0.89 0.93 0.85 0.74 0.99 0.72 0.67] \n",
      "\n",
      "Under 5.0% production error:\n",
      "[0.54 1.   0.8  0.97 0.84 0.92 0.89 0.93 0.85 0.74 0.93 0.72 0.67] \n",
      "\n",
      "Under 10.0% production error:\n",
      "[0.5  0.99 0.79 0.97 0.84 0.92 0.88 0.88 0.84 0.72 0.83 0.72 0.66] \n",
      "\n",
      "Under 20.0% production error:\n",
      "[0.42 0.94 0.77 0.96 0.83 0.9  0.86 0.77 0.77 0.7  0.7  0.72 0.65] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for e, test_epsilon in enumerate(test_epsilons):\n",
    "    print(f'Under {test_epsilon*100}% production error:')\n",
    "    print(np.round(results[:,e,0].numpy(),2) ,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10% variation aware training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epsilon = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 10, 4, 2])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = torch.zeros([13, 10, len(test_epsilons), 2])\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, test_epsilon in enumerate(test_epsilons):\n",
    "    for d, dataset in enumerate(datasets):\n",
    "        datapath = os.path.join(f'./dataset/{dataset}')\n",
    "        with open(datapath, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        X_train    = data['X_train']\n",
    "        y_train    = data['y_train']\n",
    "        X_valid    = data['X_valid']\n",
    "        y_valid    = data['y_valid']\n",
    "        X_test     = data['X_test']\n",
    "        y_test     = data['y_test']\n",
    "        data_name  = data['name']\n",
    "\n",
    "        N_class    = data['n_class']\n",
    "        N_feature  = data['n_feature']\n",
    "        N_train    = X_train.shape[0]\n",
    "        N_valid    = X_valid.shape[0]\n",
    "        N_test     = X_test.shape[0]\n",
    "\n",
    "        # generate tensordataset\n",
    "        trainset = TensorDataset(X_train, y_train)\n",
    "        validset = TensorDataset(X_valid, y_valid)\n",
    "        testset  = TensorDataset(X_test, y_test)\n",
    "\n",
    "        # batch\n",
    "        train_loader = DataLoader(trainset, batch_size=N_train)\n",
    "        valid_loader = DataLoader(validset, batch_size=N_valid)\n",
    "        test_loader  = DataLoader(testset,  batch_size=N_test)\n",
    "\n",
    "        for s, seed in enumerate(seeds):\n",
    "            setup = f'dataset:{data_name}_epsilon:{train_epsilon}_seed:{seed}'\n",
    "            model = torch.load(f'./results_variation/pNN_{setup}')\n",
    "            model.SetParameter('N', config.N_test)\n",
    "            model.SetParameter('epsilon', test_epsilon)\n",
    "            acc, std = E.BASIC_variation(model, X_test, y_test)\n",
    "            results[d,s,e,0], results[d,s,e,1] = acc, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 4, 2])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = torch.mean(results, dim=[1])\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under 0% production error:\n",
      "[0.45 1.   0.8  0.95 0.83 0.92 0.88 0.92 0.85 0.8  0.7  0.73 0.69] \n",
      "\n",
      "Under 5.0% production error:\n",
      "[0.45 1.   0.8  0.95 0.83 0.92 0.88 0.92 0.84 0.8  0.71 0.73 0.68] \n",
      "\n",
      "Under 10.0% production error:\n",
      "[0.44 1.   0.79 0.95 0.82 0.92 0.88 0.9  0.83 0.79 0.72 0.73 0.68] \n",
      "\n",
      "Under 20.0% production error:\n",
      "[0.4  0.97 0.76 0.95 0.82 0.91 0.87 0.83 0.78 0.76 0.7  0.73 0.67] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for e, test_epsilon in enumerate(test_epsilons):\n",
    "    print(f'Under {test_epsilon*100}% production error:')\n",
    "    print(np.round(results[:,e,0].numpy(),2) ,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDIL",
   "language": "python",
   "name": "sdil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
